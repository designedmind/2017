---
layout: default
title: Key claims
---

These are the main claims I will be expanding on the next few years:

* Consciousness as _designed functionality_. Like a heart is a designed
  to work as a pump, consciousness is designed to serve certain
  behavioural functions. The designer here is of course natural
  selection, not an intelligent designer. I chose to use the word
  "designed" to emphasise that consciousness serves a _function_, rather
  than being a spurious side-effect of having a certain kind of brain,
  or exhibiting a certain kind of behaviour. Consciousness is neither an
  epiphenomon nor an unobservable, private affair; it is a particular
  kind of behaviour carved out by natural selection. (Contra whoever it
  was who said -- of consciousness -- "it is impossible to say what it
  is, what it is for, or how it evolved." We absolutely can.)
* One of the key functions of consciousness is to allow an evolved agent
  to treat its own _perceptual judgements_ -- judgements which are not
  themselves conscious -- as data. Perceptual illusions are an excellent
  example. While any perceptual agent can be a _victim_ of a perceptual
  illusion, only a conscious agent can _appreciate_ one. (From an
  evolutionary point of view it is sometimes useful to be able to
  distinguish between _the way the world seems_ and the way we believe
  the world to be.) Other examples include conscious awareness of
  hallucinations induced by hallucinogenic drugs, and of optical effects
  such as parallax.
* This represention of the way the world seems does not need to take the
  form of an explicit internal image (cf. "finding out vs. filling in"
  debate). But it _is_ nevertheless a representation of the way the
  world seems. It is simply a representation which is built on an
  as-needed basis: when behaviour about "the way the world seems" is
  needed, the brain generates a judgement about the way the world seems.
  This may involve -- perhaps first initiating an action, such as a
  visual saccade, to acquire the needed information, or perhaps by
  retroactively constructing it by analysing a lingering trace of some
  earlier perceptual process. Functionally-speaking, this is
  equivalently to "eagerly" computing the represention up front, but is
  much more computationally tractable. This is essentially Dennett's
  "multiple drafts" theory of consciousness.
* Consciousness as the leading edge of perceptual memory -- yes, but not
  in the sense intended by whoever it was who said this. It's not that
  phenomenal experience comes first and is then etched down into memory;
  rather, phenomenal experience _is_ a kind of readily accessible
  perceptual memory.
* We don't get to "observe that we're conscious". We can't, as Chalmers
  does, make the "public" claim that he's "obviously conscious" from his
  own point view and have that simultaneously be a claim that is somehow
  a consequence of his having "further fact"-style consciousness.
  Rather, to _be_ a conscious agent is, at least to some extent, to be
  conscious of being conscious; this is somewhat "observation-like". But
  the minute I'm speaking to you and describing what's it like to be me,
  we're back in the realm of things that are, by definition, fully
  explicable via a physical story.
* Free-floating rationales.
* We are all "folk Cartesians".
* "Neural correlates" is a bad meme. A common intuition is that any
  representation which encodes information gives rise to a "phenomenal
  space". (Cf. neuronal workspace models, where information that is
  broadcast in a way that makes it widely available to many areas of
  processing is "conscious".) Relatedly, the intuition behind inverted
  or absent qualia is that phenomenal character is independent of
  (parallel with) function.
* When we "recall" how something looked (or how pain felt) we are not
  _remembering the phenomenology_ of vision or pain. Rather, _the
  remembering is the phenomenology_, i.e. the "phenomenology" is the
  content of the past narrative that informs our current behaviour.
* Finding out is a kind of filling in
* Zombies also have the hard problem to solve
