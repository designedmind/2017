---
layout: default
title: Key claims
---

These are the main claims I will be expanding on the next few years:

* Consciousness as _designed functionality_. Like a heart is a designed
  to work as a pump, consciousness is designed to serve certain
  behavioural functions. The designer here is of course natural
  selection, not an intelligent designer. I chose to use the word
  "designed" to emphasise that consciousness serves a _function_, rather
  than being a spurious side-effect of having a certain kind of brain,
  or exhibiting a certain kind of behaviour. Consciousness is neither an
  epiphenomon nor an unobservable, private affair; it is a particular
  kind of behaviour carved out by natural selection.
* One of the key functions of consciousness is to allow an evolved agent
  to treat its own _perceptual judgements_ -- judgements which are not
  themselves conscious -- as data. Perceptual illusions are an excellent
  example. While any perceptual agent can be a _victim_ of a perceptual
  illusion, only a conscious agent can _appreciate_ one. (From an
  evolutionary point of view it is sometimes useful to be able to
  distinguish between _the way the world seems_ and the way we believe
  the world to be.) Other examples include conscious awareness of
  hallucinations induced by hallucinogenic drugs, and of optical effects
  such as parallax.
* This represention of the way the world seems does not need to take the
  form of an explicit internal image (cf. "finding out vs. filling in"
  debate). But it _is_ nevertheless a representation of the way the
  world seems. It is simply a representation which is built on an
  as-needed basis: when behaviour about "the way the world seems" is
  needed, the brain generates a judgement about the way the world seems.
  This may involve -- perhaps first initiating an action, such as a
  visual saccade, to acquire the needed information, or perhaps by
  retroactively constructing it by analysing a lingering trace of some
  earlier perceptual process. Functionally-speaking, this is
  equivalently to "eagerly" computing the represention up front, but is
  much more computationally tractable. This is essentially Dennett's
  "multiple drafts" theory of consciousness.
* We don't get to "observe that we're conscious". We can't, as Chalmers
  does, make the "public" claim that he's "obviously conscious" from his
  own point view and have that simultaneously be a claim that is somehow
  a consequence of his having "further fact"-style consciousness.
  Rather, to _be_ a conscious agent is, at least to some extent, to be
  conscious of being conscious; this is somewhat "observation-like". But
  the minute I'm speaking to you and describing what's it like to be me,
  we're back in the realm of things that are, by definition, fully
  explicable via a physical story.
* Free-floating rationales.
